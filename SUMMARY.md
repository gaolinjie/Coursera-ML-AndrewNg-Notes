
- [week1]()

  - [一、引言(Introduction)]()
    - [1.1 欢迎](week1/一、引言/1.1欢迎.md)
    - [1.2 机器学习是什么？](week1/一、引言/1.2机器学习是什么？.md)
    - [1.3 监督学习](week1/一、引言/1.3监督学习.md)
    - [1.4 无监督学习](week1/一、引言/1.4无监督学习.md)
    - [二、单变量线性回归(Linear Regression with OneVariable)]()
    - [2.1 模型表示](week1/二、单变量线性回归/2.1模型表示.md)
    - [2.2 代价函数](week1/二、单变量线性回归/2.2代价函数.md)
    - [2.3 代价函数的直观理解I](week1/二、单变量线性回归/2.3代价函数的直观理解I.md)
    - [2.4 代价函数的直观理解II](week1/二、单变量线性回归/2.4代价函数的直观理解II.md)
    - [2.5 梯度下降](week1/二、单变量线性回归/2.5梯度下降.md)
    - [2.6 梯度下降的直观理解](week1/二、单变量线性回归/2.6梯度下降的直观理解.md)
    - [2.7 梯度下降的线性回归](week1/二、单变量线性回归/2.7梯度下降的线性回归.md)
    - [2.8 接下来的内容](week1/二、单变量线性回归/2.8接下来的内容.md)
    - [三、线性代数回顾(Linear Algebra Review)]()
    - [3.1 矩阵和向量](week1/三、线性代数回顾/3.1矩阵和向量.md)
    - [3.2 加法和标量乘法](week1/三、线性代数回顾/3.2加法和标量乘法.md)
    - [3.3 矩阵向量乘法](week1/三、线性代数回顾/3.3矩阵向量乘法.md)
    - [3.4 矩阵乘法](week1/三、线性代数回顾/3.4矩阵乘法.md)
    - [3.5 矩阵乘法的性质](week1/三、线性代数回顾/3.5矩阵乘法的性质.md)
    - [3.6 逆、转置](week1/三、线性代数回顾/3.6逆、转置.md)

- [week2]()

  - [四、多变量线性回归(Linear Regression with Multiple Variables)]()
    - [4.1 多维特征](week2/四、多变量线性回归/4.1多维特征.md)
    - [4.2 多变量梯度下降](week2/四、多变量线性回归/4.2多变量梯度下降.md)
    - [4.3 梯度下降法实践1-特征缩放](week2/四、多变量线性回归/4.3梯度下降法实践1-特征缩放.md)
    - [4.4 梯度下降法实践2-学习率](week2/四、多变量线性回归/4.4梯度下降法实践2-学习率.md)
    - [4.5 特征和多项式回归](week2/四、多变量线性回归/4.5特征和多项式回归.md)
    - [4.6 正规方程](week2/四、多变量线性回归/4.6正规方程.md)
    - [4.7 正规方程及不可逆性（可选）](week2/四、多变量线性回归/4.7正规方程及不可逆性（可选）.md)
  - [五、Octave教程(OctaveTutorial)]()
    - [5.1 基本操作](week2/五、Octave教程/5.1基本操作.md)
    - [5.2 移动数据](week2/五、Octave教程/5.2移动数据.md)
    - [5.3 计算数据](week2/五、Octave教程/5.3计算数据.md)
    - [5.4 绘图数据](week2/五、Octave教程/5.4绘图数据.md)
    - [5.5 控制语句：for，while，if语句](week2/五、Octave教程/5.5控制语句：for，while，if语句.md)
    - [5.6 向量化](week2/五、Octave教程/5.6向量化.md)
    - [5.7 工作和提交的编程练习](week2/五、Octave教程/5.7工作和提交的编程练习.md)

- [week3]()

  - [六、逻辑回归(Logistic Regression)]()
    - [6.1 分类问题](week3/六、逻辑回归/6.1分类问题.md)
    - [6.2 假说表示](week3/六、逻辑回归/6.2假说表示.md)
    - [6.3 判定边界](week3/六、逻辑回归/6.3判定边界.md)
    - [6.4 代价函数](week3/六、逻辑回归/6.4代价函数.md)
    - [6.5 简化的成本函数和梯度下降](week3/六、逻辑回归/6.5简化的成本函数和梯度下降.md)
    - [6.6 高级优化](week3/六、逻辑回归/6.6高级优化.md)
    - [6.7 多类别分类：一对多](week3/六、逻辑回归/6.7多类别分类：一对多.md)
  - [七、正则化(Regularization)]()
    - [7.1 过拟合的问题](week3/七、正则化/7.1过拟合的问题.md)
    - [7.2 代价函数](week3/七、正则化/7.2代价函数.md)
    - [7.3 正则化线性回归](week3/七、正则化/7.3正则化线性回归.md)
    - [7.4 正则化的逻辑回归模型](week3/七、正则化/7.4正则化的逻辑回归模型.md)

- [week4]()

  - [第八、神经网络：表述(Neural Networks: Representation)]()
    - [8.1 非线性假设](week4/第八、神经网络：表述/8.1非线性假设.md)
    - [8.2 神经元和大脑](week4/第八、神经网络：表述/8.2神经元和大脑.md)
    - [8.3 模型表示1](week4/第八、神经网络：表述/8.3模型表示1.md)
    - [8.4 模型表示2](week4/第八、神经网络：表述/8.4模型表示2.md)
    - [8.5 特征和直观理解1](week4/第八、神经网络：表述/8.5特征和直观理解1.md)
    - [8.6 样本和直观理解II](week4/第八、神经网络：表述/8.6样本和直观理解II.md)
    - [8.7 多类分类](week4/第八、神经网络：表述/8.7多类分类.md)

- [week5]()

  - [九、神经网络的学习(Neural Networks: Learning)]()
    - [9.1 代价函数](week5/九、神经网络的学习/9.1代价函数.md)
    - [9.2 反向传播算法](week5/九、神经网络的学习/9.2反向传播算法.md)
    - [9.3 反向传播算法的直观理解](week5/九、神经网络的学习/9.3反向传播算法的直观理解.md)
    - [9.4 实现注意：展开参数](week5/九、神经网络的学习/9.4实现注意：展开参数.md)
    - [9.5 梯度检验](week5/九、神经网络的学习/9.5梯度检验.md)
    - [9.6 随机初始化](week5/九、神经网络的学习/9.6随机初始化.md)
    - [9.7 综合起来](week5/九、神经网络的学习/9.7综合起来.md)
    - [9.8 自主驾驶](week5/九、神经网络的学习/9.8自主驾驶.md)

- [week6]()

  - [十、应用机器学习的建议(Advice for Applying Machine Learning)]()
    - [10.1 决定下一步做什么](week6/十、应用机器学习的建议/10.1决定下一步做什么.md)
    - [10.2 评估一个假设](week6/十、应用机器学习的建议/10.2评估一个假设.md)
    - [10.3 模型选择和交叉验证集](week6/十、应用机器学习的建议/10.3模型选择和交叉验证集.md)
    - [10.4 诊断偏差和方差](week6/十、应用机器学习的建议/10.4诊断偏差和方差.md)
    - [10.5 正则化和偏差/方差](week6/十、应用机器学习的建议/10.5正则化和偏差_方差.md)
    - [10.6 学习曲线](week6/十、应用机器学习的建议/10.6学习曲线.md)
    - [10.7 决定下一步做什么](week6/十、应用机器学习的建议/10.7决定下一步做什么.md)
  - [十一、机器学习系统的设计(Machine Learning System Design)]()
    - [11.1 首先要做什么](week6/十一、机器学习系统的设计/11.1首先要做什么.md)
    - [11.2 误差分析](week6/十一、机器学习系统的设计/11.2误差分析.md)
    - [11.3 类偏斜的误差度量](week6/十一、机器学习系统的设计/11.3类偏斜的误差度量.md)
    - [11.4 查准率和查全率之间的权衡](week6/十一、机器学习系统的设计/11.4查准率和查全率之间的权衡.md)
    - [11.5 机器学习的数据](week6/十一、机器学习系统的设计/11.5机器学习的数据.md)

- [week7]()

  - [十二、支持向量机(Support Vector Machines)]()
    - [12.1 优化目标](week7/十二、支持向量机/12.1优化目标.md)
    - [12.2 大边界的直观理解](week7/十二、支持向量机/12.2大边界的直观理解.md)
    - [12.3 数学背后的大边界分类（选修）](week7/十二、支持向量机/12.3数学背后的大边界分类（选修）.md)
    - [12.4 核函数1](week7/十二、支持向量机/12.4核函数1.md)
    - [12.5 核函数2](week7/十二、支持向量机/12.5核函数2.md)
    - [12.6 使用支持向量机](week7/十二、支持向量机/12.6使用支持向量机.md)

- [week8]()

  - [十三、聚类(Clustering)]()
    - [13.1 无监督学习：简介](week8/十三、聚类/13.1无监督学习：简介.md)
    - [13.2 K-均值算法](week8/十三、聚类/13.2K-均值算法.md)
    - [13.3 优化目标](week8/十三、聚类/13.3优化目标.md)
    - [13.4 随机初始化](week8/十三、聚类/13.4随机初始化.md)
    - [13.5 选择聚类数](week8/十三、聚类/13.5选择聚类数.md)
  - [十四、降维(Dimensionality Reduction)]()
    - [14.1 动机一：数据压缩](week8/十四、降维/14.1动机一：数据压缩.md)
    - [14.2 动机二：数据可视化](week8/十四、降维/14.2动机二：数据可视化.md)
    - [14.3 主成分分析问题](week8/十四、降维/14.3主成分分析问题.md)
    - [14.4 主成分分析算法](week8/十四、降维/14.4主成分分析算法.md)
    - [14.5 选择主成分的数量](week8/十四、降维/14.5选择主成分的数量.md)
    - [14.6 重建的压缩表示](week8/十四、降维/14.6重建的压缩表示.md)
    - [14.7 主成分分析法的应用建议](week8/十四、降维/14.7主成分分析法的应用建议.md)

- [week9]()

  - [十五、异常检测(Anomaly Detection)]()
    - [15.1 问题的动机](week9/十五、异常检测/15.1问题的动机.md)
    - [15.2 高斯分布](week9/十五、异常检测/15.2高斯分布.md)
    - [15.3 算法](week9/十五、异常检测/15.3算法.md)
    - [15.4 开发和评价一个异常检测系统](week9/十五、异常检测/15.4开发和评价一个异常检测系统.md)
    - [15.5 异常检测与监督学习对比](week9/十五、异常检测/15.5异常检测与监督学习对比.md)
    - [15.6 选择特征](week9/十五、异常检测/15.6选择特征.md)
    - [15.7 多元高斯分布（选修）](week9/十五、异常检测/15.7多元高斯分布（选修）.md)
    - [15.8 使用多元高斯分布进行异常检测（可选）](week9/十五、异常检测/15.8使用多元高斯分布进行异常检测（可选）.md)
  - [十六、推荐系统(Recommender Systems)]()
    - [16.1 问题形式化](week9/十六、推荐系统/16.1问题形式化.md)
    - [16.2 基于内容的推荐系统](week9/十六、推荐系统/16.2基于内容的推荐系统.md)
    - [16.3 协同过滤](week9/十六、推荐系统/16.3协同过滤.md)
    - [16.4 协同过滤算法](week9/十六、推荐系统/16.4协同过滤算法.md)
    - [16.5 向量化：低秩矩阵分解](week9/十六、推荐系统/16.5向量化：低秩矩阵分解.md)
    - [16.6 推行工作上的细节：均值归一化](week9/十六、推荐系统/16.6推行工作上的细节：均值归一化.md)

- [week10]()

  - [十七、大规模机器学习(Large Scale Machine Learning)]()
    - [17.1 大型数据集的学习](week10/十七、大规模机器学习/17.1大型数据集的学习.md)
    - [17.2 随机梯度下降法](week10/十七、大规模机器学习/17.2随机梯度下降法.md)
    - [17.3 小批量梯度下降](week10/十七、大规模机器学习/17.3小批量梯度下降.md)
    - [17.4 随机梯度下降收敛](week10/十七、大规模机器学习/17.4随机梯度下降收敛.md)
    - [17.5 在线学习](week10/十七、大规模机器学习/17.5在线学习.md)
    - [17.6 映射化简和数据并行](week10/十七、大规模机器学习/17.6映射化简和数据并行.md)
  - [十八、应用实例：图片文字识别(Application Example: PhotoOCR)]()
    - [18.1 问题描述和流程图](week10/十八、应用实例：图片文字识别/18.1问题描述和流程图.md)
    - [18.2 滑动窗口](week10/十八、应用实例：图片文字识别/18.2滑动窗口.md)
    - [18.3 获取大量数据和人工数据](week10/十八、应用实例：图片文字识别/18.3获取大量数据和人工数据.md)
    - [18.4 上限分析：哪部分管道的接下去做](week10/十八、应用实例：图片文字识别/18.4上限分析：哪部分管道的接下去做.md)
  - [十九、总结(Conclusion)]()
    - [19.1 总结和致谢](week10/十九、总结/19.1总结和致谢.md)
